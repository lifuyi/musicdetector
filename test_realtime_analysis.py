#!/usr/bin/env python3
"""
Test script to verify the real-time analysis improvements
Simulates the Mac app's analysis process
"""

import numpy as np
import time
import json
from typing import Dict, List, Optional

class MockAudioFeatures:
    """æ¨¡æ‹ŸéŸ³é¢‘ç‰¹å¾æ•°æ®"""
    def __init__(self, chroma: List[float], magnitude: List[float], timestamp: float):
        self.chroma = chroma
        self.magnitude = magnitude
        self.timestamp = timestamp

class MockMusicAnalysisEngine:
    """æ¨¡æ‹ŸMac appçš„éŸ³ä¹åˆ†æå¼•æ“"""
    
    def __init__(self):
        self.feature_history = []
        self.onset_strengths = []
        self.bpm_estimate = 120.0  # é»˜è®¤BPM
        self.has_valid_bpm = True
        self.current_key = None
        self.chord_history = []
        
        # ä¼˜åŒ–çš„å‚æ•°
        self.key_confidence_threshold = 0.05  # ä»0.001æé«˜åˆ°0.05
        self.beat_history_size = 30  # ä»50å‡å°‘åˆ°30
        self.min_onset_count = 3  # ä»10é™åˆ°3
        
        # éŸ³ç¬¦åç§°
        self.note_names = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]
        
        # è°ƒå¼ç‰¹å¾
        self.key_profiles = {
            "major": [6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88],
            "minor": [6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17]
        }
    
    def generate_mock_features(self, bpm: float = 120.0, key: str = "C", mode: str = "major") -> MockAudioFeatures:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„éŸ³é¢‘ç‰¹å¾æ•°æ®"""
        timestamp = time.time()
        
        # ç”Ÿæˆè‰²åº¦ç‰¹å¾ï¼ˆåŸºäºè°ƒå¼ï¼‰
        chroma = self.key_profiles[mode].copy()
        
        # æ·»åŠ ä¸€äº›éšæœºå˜åŒ–
        chroma = [c + np.random.normal(0, 0.1) for c in chroma]
        chroma = [max(0, c) for c in chroma]  # ç¡®ä¿éè´Ÿ
        
        # å½’ä¸€åŒ–
        chroma_sum = sum(chroma)
        if chroma_sum > 0:
            chroma = [c / chroma_sum for c in chroma]
        
        # ç”Ÿæˆå¹…åº¦ç‰¹å¾ï¼ˆæ¨¡æ‹ŸèŠ‚æ‹ï¼‰
        magnitude = [np.random.random() * 0.5 + 0.5 for _ in range(128)]
        
        # æ ¹æ®BPMæ·»åŠ èŠ‚æ‹æ¨¡å¼
        beat_phase = (timestamp * bpm / 60.0) % 1.0
        if beat_phase < 0.1:  # é‡æ‹
            magnitude = [m * 1.5 for m in magnitude]
        
        return MockAudioFeatures(chroma, magnitude, timestamp)
    
    def analyze_beat(self, features: MockAudioFeatures) -> Dict:
        """åˆ†æèŠ‚æ‹ - æ”¹è¿›ç‰ˆæœ¬"""
        current_time = features.timestamp
        
        # è®¡ç®—onsetå¼ºåº¦
        onset_strength = self.calculate_onset_strength(features)
        self.onset_strengths.append(onset_strength)
        
        # ä¿æŒåˆç†çš„å†å²é•¿åº¦
        if len(self.onset_strengths) > 50:
            self.onset_strengths.pop(0)
        
        print(f"ğŸ“Š Onset detection: {len(self.onset_strengths)}/3 samples, current strength: {onset_strength:.3f}")
        
        # ç«‹å³å¼€å§‹åˆ†æï¼Œå³ä½¿æ•°æ®è¾ƒå°‘
        if len(self.onset_strengths) < 3:
            print(f"â³ Initializing beat detection (current: {len(self.onset_strengths)}/3)...")
            return {
                "bpm": self.bpm_estimate,
                "confidence": 0.1,
                "beat_position": 0.0,
                "measure_position": 1
            }
        
        # ç®€åŒ–çš„èŠ‚æ‹è·Ÿè¸ª
        beat_info = self.track_beats(onset_strengths=self.onset_strengths, current_time=current_time)
        
        print(f"ğŸ¯ Beat tracking result: BPM={beat_info['bpm']:.1f}, Confidence={beat_info['confidence']:.2f}")
        
        # æ›´å¿«æ›´æ–°BPMä¼°è®¡
        if beat_info["bpm"] > 0 and beat_info["confidence"] > 0.01:
            self.bpm_estimate = beat_info["bpm"]
            self.has_valid_bpm = True
            print(f"âœ… BPM updated: {self.bpm_estimate}")
        elif beat_info["bpm"] > 0 and len(self.onset_strengths) > 10:
            # æ•°æ®è¶³å¤Ÿå¤šæ—¶ï¼Œå³ä½¿ç½®ä¿¡åº¦ç¨ä½ä¹Ÿæ¥å—
            self.bpm_estimate = beat_info["bpm"]
            self.has_valid_bpm = True
            print(f"âš ï¸ BPM accepted with sufficient data: {self.bpm_estimate}")
        
        return beat_info
    
    def analyze_key(self) -> Optional[Dict]:
        """åˆ†æè°ƒå¼ - æ”¹è¿›ç‰ˆæœ¬"""
        if len(self.feature_history) < 1:
            print(f"ğŸµ Key detection: waiting for feature data (current: {len(self.feature_history)})")
            return None
        
        print(f"ğŸµ Starting key detection with {len(self.feature_history)} feature samples")
        
        # ä½¿ç”¨æ›´å¿«çš„åˆ†æç­–ç•¥
        recent_feature_count = min(20, len(self.feature_history))
        recent_features = self.feature_history[-recent_feature_count:]
        
        # è®¡ç®—åŠ æƒè‰²åº¦ç‰¹å¾
        weighted_chroma = [0.0] * 12
        total_weight = 0.0
        
        for index, features in enumerate(recent_features):
            weight = (index + 1) / len(recent_features)  # è¶Šæ–°çš„æƒé‡è¶Šå¤§
            for i in range(12):
                weighted_chroma[i] += features.chroma[i] * weight
            total_weight += weight
        
        # å½’ä¸€åŒ–
        if total_weight > 0:
            weighted_chroma = [c / total_weight for c in weighted_chroma]
        
        # å¿«é€Ÿè°ƒå¼æ£€æµ‹
        key_scores = []
        for root in range(12):
            for mode in ["major", "minor"]:
                score = self.calculate_fast_key_score(weighted_chroma, root, mode)
                key_scores.append({
                    "root": root,
                    "mode": mode,
                    "score": score
                })
        
        # æ’åºè·å¾—æœ€ä½³åŒ¹é…
        key_scores.sort(key=lambda x: x["score"], reverse=True)
        
        best_score = key_scores[0]["score"]
        print(f"ğŸµ Key detection: best score: {best_score:.4f}")
        
        if best_score >= self.key_confidence_threshold:
            best_key = key_scores[0]
            key_name = self.note_names[best_key["root"]]
            mode_name = "å¤§è°ƒ" if best_key["mode"] == "major" else "å°è°ƒ"
            
            print(f"ğŸµ Key detection successful: {key_name} {mode_name} (confidence: {best_score})")
            
            return {
                "root": best_key["root"],
                "mode": best_key["mode"],
                "confidence": best_score,
                "name": f"{key_name} {mode_name}"
            }
        else:
            # æ•°æ®è¶³å¤Ÿå¤šæ—¶ï¼Œå³ä½¿ç½®ä¿¡åº¦ç¨ä½ä¹Ÿè¿”å›ç»“æœ
            if len(self.feature_history) > 15 and best_score > self.key_confidence_threshold * 0.5:
                best_key = key_scores[0]
                key_name = self.note_names[best_key["root"]]
                mode_name = "å¤§è°ƒ" if best_key["mode"] == "major" else "å°è°ƒ"
                
                print(f"ğŸµ Key detection: accepting lower confidence with sufficient data")
                return {
                    "root": best_key["root"],
                    "mode": best_key["mode"],
                    "confidence": best_score * 0.8,
                    "name": f"{key_name} {mode_name}"
                }
            
            print(f"ğŸµ Key detection failed: score {best_score:.4f} < threshold {self.key_confidence_threshold}")
            return None
    
    def calculate_onset_strength(self, features: MockAudioFeatures) -> float:
        """è®¡ç®—èµ·å§‹å¼ºåº¦"""
        if not self.feature_history:
            return 0.0
        
        previous_features = self.feature_history[-1]
        
        # è®¡ç®—è°±é€šé‡
        spectral_flux = 0.0
        for i in range(min(len(features.magnitude), len(previous_features.magnitude))):
            diff = features.magnitude[i] - previous_features.magnitude[i]
            if diff > 0:
                spectral_flux += diff
        
        return spectral_flux
    
    def calculate_fast_key_score(self, chroma: List[float], root: int, mode: str) -> float:
        """å¿«é€Ÿè°ƒå¼è¯„åˆ†ç®—æ³•"""
        profile = self.key_profiles[mode]
        
        # ç®€åŒ–çš„ç›¸å…³æ€§è®¡ç®—
        correlation = 0.0
        profile_sum = sum(profile)
        
        for i in range(12):
            rotated_index = (i + root) % 12
            correlation += chroma[i] * profile[rotated_index]
        
        # å½’ä¸€åŒ–
        normalized_correlation = correlation / profile_sum if profile_sum > 0 else 0
        
        # ä¸»éŸ³å¼ºåº¦å¥–åŠ±
        tonic_bonus = chroma[root] * 0.2
        
        return normalized_correlation + tonic_bonus
    
    def track_beats(self, onset_strengths: List[float], current_time: float) -> Dict:
        """ç®€åŒ–çš„èŠ‚æ‹è·Ÿè¸ª"""
        if len(onset_strengths) < 3:
            return {
                "bpm": self.bpm_estimate,
                "confidence": 0.1,
                "beat_position": 0.0,
                "measure_position": 1
            }
        
        # ç®€å•çš„å³°å€¼æ£€æµ‹
        peaks = []
        for i in range(1, len(onset_strengths) - 1):
            if (onset_strengths[i] > onset_strengths[i-1] and 
                onset_strengths[i] > onset_strengths[i+1] and
                onset_strengths[i] > 0.1):
                peaks.append(i)
        
        if len(peaks) > 1:
            # è®¡ç®—å¹³å‡é—´éš”
            intervals = []
            for i in range(1, len(peaks)):
                intervals.append(peaks[i] - peaks[i-1])
            
            avg_interval = sum(intervals) / len(intervals)
            # è½¬æ¢ä¸ºBPM (å‡è®¾é‡‡æ ·ç‡ä¸º ~43Hz)
            estimated_bpm = 60.0 * 43.0 / avg_interval
            
            # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
            if 60 <= estimated_bpm <= 200:
                confidence = min(1.0, len(peaks) / 10.0)
                return {
                    "bpm": estimated_bpm,
                    "confidence": confidence,
                    "beat_position": (current_time % 1.0),
                    "measure_position": int(current_time % 4) + 1
                }
        
        return {
            "bpm": self.bpm_estimate,
            "confidence": 0.1,
            "beat_position": (current_time % 1.0),
            "measure_position": int(current_time % 4) + 1
        }
    
    def run_simulation(self, duration_seconds: int = 10, target_bpm: float = 120.0, target_key: str = "C"):
        """è¿è¡Œæ¨¡æ‹Ÿæµ‹è¯•"""
        print(f"ğŸµ å¼€å§‹å®æ—¶åˆ†ææ¨¡æ‹Ÿæµ‹è¯•")
        print(f"ğŸ¯ ç›®æ ‡: BPM={target_bpm}, Key={target_key}")
        print(f"â±ï¸  æŒç»­æ—¶é—´: {duration_seconds}ç§’")
        print("=" * 50)
        
        start_time = time.time()
        iteration = 0
        
        while time.time() - start_time < duration_seconds:
            iteration += 1
            current_time = time.time() - start_time
            
            # ç”Ÿæˆæ¨¡æ‹ŸéŸ³é¢‘ç‰¹å¾
            features = self.generate_mock_features(bpm=target_bpm, key=target_key)
            self.feature_history.append(features)
            
            # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
            if len(self.feature_history) > 100:
                self.feature_history.pop(0)
            
            # åˆ†æèŠ‚æ‹
            beat_result = self.analyze_beat(features)
            
            # åˆ†æè°ƒå¼
            key_result = self.analyze_key()
            
            # æ˜¾ç¤ºç»“æœ
            print(f"\nâ° æ—¶é—´: {current_time:.1f}s, è¿­ä»£: {iteration}")
            print(f"ğŸ¥ èŠ‚æ‹: BPM={beat_result['bpm']:.1f}, ç½®ä¿¡åº¦={beat_result['confidence']:.2f}")
            
            if key_result:
                print(f"ğŸ¼ è°ƒå¼: {key_result['name']}, ç½®ä¿¡åº¦={key_result['confidence']:.3f}")
            else:
                print(f"ğŸ¼ è°ƒå¼: æ£€æµ‹ä¸­... (å†å²æ•°æ®: {len(self.feature_history)})")
            
            # æ¨¡æ‹ŸéŸ³é¢‘å¤„ç†é—´éš” (~100ms)
            time.sleep(0.1)
        
        print("\n" + "=" * 50)
        print(f"âœ… æ¨¡æ‹Ÿæµ‹è¯•å®Œæˆ")
        print(f"ğŸ“Š æœ€ç»ˆBPM: {self.bpm_estimate:.1f}")
        if self.current_key:
            key_result = self.analyze_key()
            if key_result:
                print(f"ğŸ“Š æœ€ç»ˆè°ƒå¼: {key_result['name']}")
        print(f"ğŸ“Š æ€»è¿­ä»£æ¬¡æ•°: {iteration}")

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    engine = MockMusicAnalysisEngine()
    
    # æµ‹è¯•1: æ ‡å‡†é€Ÿåº¦å’Œè°ƒå¼
    print("ğŸ§ª æµ‹è¯•1: æ ‡å‡†å‚æ•° (BPM=120, Key=C)")
    engine.run_simulation(duration_seconds=5, target_bpm=120.0, target_key="C")
    
    print("\n" + "="*60 + "\n")
    
    # æµ‹è¯•2: å¿«é€Ÿåº¦å’Œä¸åŒè°ƒå¼
    print("ğŸ§ª æµ‹è¯•2: å¿«é€Ÿåº¦å’ŒDå°è°ƒ (BPM=140, Key=D)")
    engine = MockMusicAnalysisEngine()  # é‡ç½®å¼•æ“
    engine.run_simulation(duration_seconds=5, target_bpm=140.0, target_key="D")
    
    print("\n" + "="*60 + "\n")
    
    # æµ‹è¯•3: æ…¢é€Ÿåº¦å’ŒFå¤§è°ƒ
    print("ğŸ§ª æµ‹è¯•3: æ…¢é€Ÿåº¦å’ŒFå¤§è°ƒ (BPM=80, Key=F)")
    engine = MockMusicAnalysisEngine()  # é‡ç½®å¼•æ“
    engine.run_simulation(duration_seconds=5, target_bpm=80.0, target_key="F")